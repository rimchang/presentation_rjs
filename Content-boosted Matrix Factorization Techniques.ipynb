{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Matrix factorization: A brief review\n",
    "\n",
    "## 2.1 Notation\n",
    "\n",
    "$U = \\{ u_1,...,u_N \\}$ - set of user  \n",
    "$I = \\{ i_1,...,i_N \\}$ - set of Item  \n",
    "$R = [r_{ui}]_{NxM}$ - rating matrix\n",
    "\n",
    "r_ui 는 결국 u user가 i item 에게 매긴 rating 이다. 이는 원칙적으로는 실수이지만 실무적으로는 dislike, like 같은 binary 한 값이거나 [1,5] 사이의 어떤 range를 가진 수이다\n",
    "\n",
    "rating matrix R은 매우 Sparse한 데이터이기 때문에 cold start 문제가 발생한다\n",
    "\n",
    "$T = \\{(u,i): r_{ui} is known\\}$ - 알려진 r_ui 들을 T라고 나타낸다.recommender system 의 목적은 알려지지 않은 나머지의 r_ui 들을 예측하는 것이다. 그리고 예측한 rating을 <bold>$\\hat{r_{ui}}$</bold> 라고 표시한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalization by ANOVA\n",
    "\n",
    "ANOVA - type model은 유용한 정보를 이끌어 낼 수 있다. 가장 간단한 ANOVA - type model 은 r_ui 를 다음과 같다고 생각한다\n",
    "\n",
    "$r_{ui} = \\mu + \\alpha_{u} + \\beta_{i} + \\epsilon_{ui} $\n",
    "\n",
    "$ \\epsilon_{ui} $ 은 노이즈를 나타내며 \\mu 는 총 평균, 알파와 베타는 각각 user effect, item effect를 나타낸다. 이 두가지 주효과는 몇가지를 알게 해주는데 어떤 아이템들은 다른 아이템들보다 일반적으로 더 좋아하고 some users are simply more difficult to please.\n",
    "\n",
    "보통 mf or nn methods 를 사용하기 전에 이런 ANOVA - type model을 사용하여 normalize 하는 것이 일반적이다. 우리도 모든 mf algorithm에 $r_{ui} - \\mu - \\alpha_{u} - \\beta_{i} $ 를 적용했으며 예측된 rating은 실제로 $r_{ui} + \\mu + \\alpha_{u} + \\beta_{i} $ 이다. $\\hat{r_{ui}}$ 은 mf 알고리즘에 의해 예측된 rating 이며 $\\hat{\\mu},\\hat{ \\alpha},\\hat{\\beta} $ 은 $\\mu, \\alpha,\\beta $의 MLEs 추정치 들이다. notation의 혼동을 줄이기 위하여 우리는 normalization step 을 거친 R 이라도 r_ui 로 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Matrix factorization\n",
    "\n",
    "R에서의 Unkonwn rating을 예측하기 위해서 우리는 mf 알고리즘을 적용했다. 이는 matrix R을 2가지 low-rank 의 , latent feature matrices 로 나타내는 것이다. \n",
    "\n",
    "$ R \\approx \\hat{R} = PQ^T = [p^T_1,p^T_2,...,p^T_N]^T[q_1,q_2,...q_M]$\n",
    "\n",
    "latent feature veotor p_u 는 유저를 나타내는 것이고, q_I 은 아이템을 나타내는 것이다. 이는 모두 K차원이며 k는 m,n보다 작다. 이러면 $\\hat{r_{ui}} = p_u^Tqi$ 로 간단히 나타내진다.\n",
    "\n",
    "직관적으로 k차원의 사상을 생각 해 볼수 있다. 여기서 p_u와 q_i 는 (latent) coordinates for user and item 이다. 개별적으로 우리가 추천을 하기 위해 필요한 모든 정보는 이 사상 속에 담겨져 있다. Latent-coordiante model 은 긴 역사를 가지고 있는으며 pca, 요인분석, 다변량분석 등등이다.\n",
    "\n",
    "수학적으로 factorization 은 밑의 최적화 문제를 푸는 것으로 풀리는데\n",
    "\n",
    "$min_{P,Q} ||R-PQ^T||^2 $ 를 푸는 것으로 solve 되며 Frobenius norm 이라면 overfitting 을 피하기 위해 regularization 을 해주며 그렇게 되면 밑의 수식으로 전개된다.\n",
    "\n",
    "$min_{P,Q} ||R-PQ^T||^2 + \\lambda(||P||^2+||Q||^2)$\n",
    "\n",
    "\n",
    "베이지안의 관점에서 살펴보면 위의 수식의 앞부분은 Gaussian likelihood function 에서 나온 거이고 뒤의 식은 spherical(구체의) Gaussian priors on the user and item feature vectors 에서 나온 것이다. 위의 수식은 MAP 를 통해 최적화 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Relative scaling of penalty terms\n",
    "\n",
    "Feuerverger 은 empirical bayes analysis 를 여기에 적용했는데 이는 각각의 user, item 에 패널티텀 $||P||^2,||Q||^2$을 다르게 적용한 것이다. 실무적으로 이런 충고는 언제나 적용된건 아니였는데 이는 계산량의 소모와 성능이 많이 상승되지는 않았기 때문이다.\n",
    "\n",
    "우리의 작업에서는 두번째 패널티 텀$||Q||^2$ - (factor r >0 에 의해 패널티를 받음) 을 쉽게 찾는 방법을 찾아 내었으며 n(N), n(M)에 상관없이 Q의 패널티 텀이 P의 패널티 텀에 order of magnitude (지수만큼??,,모르겟음)만큼 같다는 것을 찾았다.\n",
    "\n",
    "추가적으로 R의 대부분이 unknown 이기 때문에 우리는 object function의 첫번째 텀을 알려진 entrie T를 가지고 평가했다(Base line 사용했다는 뜻인듯) \n",
    "\n",
    "${minimize}\\, L_{BL}(P,Q) = \\sum {(r_{ui} - \\hat r_{ui})^2 + \\lambda (\\sum_u {||p_u||}^2 + r\\sum_i {||q_i||}^2)}$\n",
    "\n",
    "BL의 표시는 Baseline 사용했다는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Alternating gradient descent\n",
    "\n",
    "P,Q가 unknown 이기 때문에 convex하지가 않다. 이것은 gradent descent의 다른 대체적인 방법을 사용해야 하는 것을 의미하는데 Q를 고정하고 가장 잘 설명하는 P를 찾고, P를 고정하고 가장 잘 설명하는 Q를 찾는 과정을 반복적으로 왔다갔다 하면서 값을 찾는다. \n",
    "\n",
    "<img src='./ficture/gd_forbl.JPG' width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 SVD and other matrix factorization techniques\n",
    "\n",
    "CF 논문들에서 위의 MF 접근 방법은 보통 SVD 로 불려지는데 이는 엄격하게 말하면 잘못된 말이다. SVD는 아마도 MF 테크닉 중에서 가장 많이 쓰이는 것이다. 같은 것은 아니다.\n",
    "\n",
    "\n",
    "<img src='./ficture/SVD_algoritm.JPG' width=600 />\n",
    "\n",
    "\n",
    "D* 는 대각 행렬이고 P,Q는 직교행렬이다. MF 접근 방식은 위로 요약되는데 이것은 P,Q가 직교하는 것을 필요로 하는 것이 아니다. 이 방식을 사용해서 넷플릭스 경연의 우승자에 따르면 직교행렬이여야 한다는 제약조건이 없으면 this would certainly raise identifiability and degeneracy questions for the optimization problem (뭐 이론적으로는 그러면 안된다는 말인듯) 하지만 실무적으로 초기화를 잘하면 피해갈 수 있다고 한다.\n",
    "\n",
    "Lee, seung은 다른 mf 기술을 만드었는데 non-negative matrix factoriztion(NMF) 라고 한다 이는 non-negativity constraints 가 추가가 된 것이고\n",
    "\n",
    "$P_{UK} , Q_{IK} >=0 for all u,i,k$ 라는 조건이 추가가 된 것이다. NMF 는 underlying structure을 밝히기 위해 이미지나 유전학등 에서 사용되던 것이\n",
    "다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Content-boosted matrix factorization\n",
    "\n",
    "이제 가정을 해보는데 각각의 아이템 I 마다 content vector $a_i = [a_{i1},a_{in},...,a_{iD}]$의 D개의 변수가 존재 한다고 생각해보자 이를 쌓아서 A=[a_id] 라는 메트릭스로 만들 수 있다. 여기서는 간단하게 A가 0,1로 binary 하다고 가정했다. \n",
    "\n",
    "# 3.1 Alignment-biased factorization\n",
    "\n",
    "mf 알고리즘에 A를 포함하기 위한 아이디어중 하나는 두아이템 I_1,I_2 가 적어도 C attribute를 공유 할 것이다. (if two items\n",
    "i and i′ share at least c attributes in common) 이것은 \"common attributes\" 조건이라고 한다. 그러면 이것은 직관적으로 이들의 latent feature vector q_i_1, q_i_2 가 가까울 것이다 latent space 안에서.\n",
    "\n",
    "## 3.1.1 Details\n",
    "\n",
    "mf 접근을 위해 위에서 봤던 $ R \\approx \\hat{R} = PQ^T = [p^T_1,p^T_2,...,p^T_N]^T[q_1,q_2,...q_M]$ 의 수식에서 closeness 라는 것은 latent feature space의 내적으로 모델링 되어 있다. 그러므로 q_i_1, q_i_2 의 \"close\"는 이 둘의 내적을 뜻한다. 즉 내적이 커지면 close(거리?)가 가깝다는 뜻이다. 우리는 여기에 패널티를 추가 할 것이다 이를 alignment penalty 라고 한다. 이를 최적화 하기 위해서\n",
    "\n",
    "binary 한 a_id 에서 $a^T_i1a_i2 >= c$ 즉 둘의 내적이 c보다 큰 조건의  \"common attributes\" 는 밑과 같이 표현된다.\n",
    "\n",
    "내가이해하기엔...\n",
    "\n",
    "즉 S_c(i) 는 내적(두 벡터간의 크기?라고 볼수 있나) 이 c보다 큰 놈들의 인덱스를 모아놓은 집합이라고 할 수 있을 것 같음 S_c(i) = {3, 5,10,11} 이런식으로... 물론 자기 자신을 제외하고!! 그래서 i\\`!=i 조건이 있는듯 그니까.. 밑의 노테이션을 살펴보면.. attributes vector 가 거리가 가까운 놈들만 고려해서 빼주겟다..?? 잘 이해가안간다\n",
    "\n",
    "\n",
    "\n",
    "<img src='./ficture/alignment_mf.JPG' width=600 />\n",
    "\n",
    "내적의 의미가 무엇이지..? proj vector의 크기,,, 헷갈린다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.1.2 Differential shrinkage effects(다른 수축현상?\n",
    "\n",
    "alignment penalty 의 효과는 명쾌한데 몇가지의 attributes를 공유하는items의 중심으로 latent factor 가 수축된다. selective shrinkage effect 라는 것이다.\n",
    "\n",
    "다음은 alignment penalty의 generalized,smoothed 된 버젼을 볼텐데. 거의 비슷하지만 수학적 포뮬러가 다르다. 우리는 각각의 알고리즘의 다른점을 살펴 볼 것인데 이들 알고리즘은 qi를 약간 다른 중심점으로 향하게 하는 것일뿐 아이디어느 비슷하다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.2 A smooth generalization\n",
    "\n",
    "\n",
    "- 기계 학습에서의 일반화는 훈련 이후 새롭게 들어온 데이터를 정확히 처리할 수 있는 능력을 말한다. 기계 학습의 핵심은 표현(representation)과 일반화(generalization)에 있다. 표현이란 데이터의 평가이며, 일반화란 아직 알 수 없는 데이터에 대한 처리이다. 이는 전산 학습 이론 분야이기도 하다. 다양한 기계 학습의 응용이 존재한다. 문자 인식은 이를 이용한 가장 잘 알려진 사례이다.\n",
    "\n",
    "alignment penalty의 분명한 일반화는 다음과 같다.\n",
    "\n",
    "<img src='./ficture/GAB.JPG' width=600 />\n",
    "\n",
    "(15) 는 비례하는 관계를 나타낸다. W(i,i\\`) 는 attribute vector를 nomalization 한 것이다. 그결과 W(i,i\\`) 의 i에 대한 합은 1이 될것이다. 위에서 봤던 alignment penalty (12)는 지금 바로위의 수식인 (15) 에서의 세타가 무한대로 갈떄의 경우와 같다.  W(i,i\\`)는 item i, i\\`가 공유하고 있는 attribute의 갯수의  smooth, monotic 된 함수이다. \n",
    "\n",
    "L_gAB 의 P_u에 대한 그라디언트는 기존의 BL, AB 같으며 q_i 에 대한 미분은 (16)과 같다.\n",
    "\n",
    "smooth한 weight를 사용함으로써 shared attribute를 shrinkage effect를 item마다 다르게 할 수 있게 한다. 그래서 아이템 마다 다른 shrinkage effects를 가지게 하고 alignment penalty의 효과를 높이게 한다. Figure1 을 보면 세타값에 따른 w의 변화를 볼 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.4 A related method: Tag informed CF\n",
    "\n",
    "많은 commercial 추천 엔진에서 유저들에게 tag를 잘 수 있게 한다. Zhen은 이런 태그를 사용하는 방법을 제안했다. Li and Yeung의 연구의 아이디어는 \"만약 두 유저의 tagging history가 비슷하다면 latent feature vectors를 비슷하게 만드는 것\" 이며 이를 위해 tag-based penalty를 L_bl 에 추가했다. \n",
    "\n",
    "<img src='./ficture/tag_based.JPG' width=600 />\n",
    "\n",
    "w(u,u\\`) 은 두유저의 tagging history의 유사도 를 측정한 것이다. 재밌게도 우리는 user를 item 으로 바꾸고 tagging history 를 item attributes로 바꿀 수 있었고 이는 item에 같은 아이디어를 적용한 것이다.\n",
    "\n",
    "item에 적용 했을때 w(i,i\\`) 는 그들의 content information 사이의 유사도 이다. 밑의 수식에서 TG는 tag 알고리즘을 적용했다는 뜻이다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Regression-constrained factorization\n",
    "\n",
    "매트릭스 A에 content information을 포함 할 수 있는 다른 아이디어는 regression-style 제약을 사용 하는 것이다. item feature vector 를 item's content attributes 의 함수로 강제 함으로써 같은 attributes 를 가진 item 들을 같은 feature vector로 사상 시킬 수 있다. 이런 방법은 우리가 처음 제안했었따.\n",
    "\n",
    "## 3.2.1 Details\n",
    "\n",
    "구체적으로 말하면 제약 조건은 다음과 같다\n",
    "\n",
    "$Q = AB$\n",
    "\n",
    "B 는 D * K 매트릭스고 B의 칼럼은 regression coefficient 처럼 작동한다. 이것은 content attributes 를 사용하여 아이템을 latent feature 로 사상한다. B의 각각의 행은 attribute 의 k차원의 latent feature로 볼 수 있다.\n",
    "\n",
    "<img src='./ficture/regression_based.JPG' width=600 />\n",
    "\n",
    "## Related literature\n",
    "\n",
    "regression based 의 아디이어는 오랜 역사를 가지고 있다. 예를 들어 ecologists 는 이것의 다변량 적인 기술을 correspondence analysis 라고 사용하고 있고 latent coordinates를 사용하여 species와 geographical sites를 분류하는데 사용한다. 비슷한 조건을 가진 sites는 coordinates가 가까울 것이고, species 는 비슷한 환경을 선호 한다. 이들은 제약을 거는데 latent site coordinates 가 그 장소의 실제 environmental measurements의 선형 함수라는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Experiments\n",
    "\n",
    "이번 섹션에서는 우리가 사용한 데이터를 설명하고 다양한 content-boosted MF 알고리즘을 baseline MF와 비교할 것이다. \n",
    "\n",
    "## 4.1 The scaling factor γ\n",
    "\n",
    "우리가 이전에 말했듯이 scaling facotr r은 두 패널티를 균형있게 만들어 주게 되고 그 결과 objective function is not dominated by either the user or the item\n",
    "side of the equation. (user or item 어느 한쪽으로 치우치지 않게함???) . 이 논문에서는 $\\sum{p_U}^2$ 를 상수로 방ㅅ기 때문에 알고리즘은 q_i 의 scaling factor 에만 영향을 받는다. r을 사용함으로써 모든 알고리즘을 같은 scale에서 비교할 수 있게 해준다. BL,AB,gAB 에서는 r=N/M 을 사용하며 RC 에서는 N/D 를 사용한다. TG 에서는 weights들이 normailized 되었기 대문에 r=N/3M 을 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Data sets\n",
    "\n",
    "우리는 Recipes, Movies 의 두가지 데이터 셋을 사용했다. 레시피는 http://allrecipes.com/ 를 크롤링 하엿고 90명 이상에게 평가받은 recipes와 50개 이상을 평가한 user를 사용하였다. Movies 데이터는 무비렌즈를 사용했다.\n",
    "\n",
    "레시피 데이터는 0~5사이의 rating을 가지고 있으며 binary attribute 는 recipe i 가 ingredient d를 포함하느지 안하는지이다. 무비 데이터는 1~5사이의 rating 을 가지고 있고 attribute로 영화 i 가 genre d에 속하는지 이다. (하나의 영화가 여러 장르를 가질 수 있다)\n",
    "\n",
    "# 4.3 Evaluation\n",
    "\n",
    "서로 다른 알고리즘을 평가하기 위해 우리는 같은 실험을 15번 반복했다. 각각의 반복마다 우리는 user-item pairs (u,i) 를 50%는 traning set, 50% test set 으로 구성하였다. test-set 에서의 known rating 을 사용하여 우리는 P,Q 를 학습시켰다. test-set 의 (u,i) 는 모두 $\\hat{r_{ui}}=p^T_uq_i$를 사용해서 예측하였다. (적절한 truncation를 사용해서 [0,5] 혹은 [1,5] 로 짤랏다..) - 어떻게 했다는 걸까... 그리고 MAE 를 통해 평가하였다\n",
    "\n",
    "# $MAE = \\frac{1}{|T`|}\\sum_{(u,i)}{r_{ui}-\\hat{r_{ui}}}$\n",
    "\n",
    "많은 연구자들이 MAE 는 discrete rating 에 적절하다고 말하지만 RMSE 대신 MAE를 선호하는 논문들이 많다. 각각의 알고리즘에서 K=5,10,15 로 실험하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Additional details for AB and gAB\n",
    "\n",
    "무비, 레시피 데이터 모두 대부분의 아이템들이 attribute를 공유하지 않는 것이 많았다. attributes를 공유하는 것이 매우 적기 때문에 (무비렌즈는 2/3 이 0개 이고 레시피는 1/2 이 0개를 공유) 우리는 AB,gAB에 c=1 을 선택하였다. 즉 공유하는 attribute가 하나라도 있으면 alignment penalty를 주라는 의미. \n",
    "일반적으로 말해서, c를 AB에 대한 추가 튜닝 파라미터로 간주 할 수 있지만,\n",
    "성능이 MAE 나 RMSE와 같은 전체적 메트릭으로 측정된다면,then the range of reasonable choices for c is fairly limited in our opinion. \n",
    "\n",
    "우리는 c를 10%~50%의 item-pair 가 영향을 받도록 선택하는 것이 최상이라고 생각한다. 만약 너무 적은수의 item-pair 가 영향을 받게 된다면 MAE 나 RMSE 에 영향이 별로 없을 것이다. 만약 50% 보다 많이 영향을 받게 된다면 items would almost certainly be shrunken blindly toward those with which they have little in common(뭐하여튼 안좋다). x의 range의 제한때문에 실제로 c의 선택에 제한을 받는다 \n",
    "\n",
    "예를 들면 무비렌즈에서는 c>=2 로 하면 2.2% 이하의 데이터가 영향을 받고 c=0 으로 하면 100% 영향을 받는다. 그래서 합리적인 c=1로 골랐고 35%정도가 영향을 받는다. gAB에서는 세타값이 크면 클수록 AB처럼 움직인다. 반면에 세타값이 작으면 alignment penalty를 덜받는다. 우리는 세타=1을 사용했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Initialization\n",
    "\n",
    "우리가 이전에 언급했듯이 P,Q 를 둘다 모르기 때문에 convex한 문제가 아니다. 이 의미는 alternating gradient descent 알고리즘이 local minima에 빠질 수 있다는 뜻이다. 그래서 좋은 initializaion 전략이 쓸모있다.\n",
    "\n",
    "## 4.5.1 SVD strategy\n",
    "\n",
    "K가 주어졌을때의 P,Q 의 초기화 방법은 다음과 같다\n",
    "\n",
    "먼저 impute the missing entries of R with predictions from a certain rudimentary model (R 매트릭스의 missing 값들을 기본적인 모델을 통해 채워 넣는다) - 이를 R\\* 라고 하고 SVD를 통해 R\\*를 근사한다.\n",
    "\n",
    "# $R_* \\approx P_*D_*Q_*^T$ \n",
    "\n",
    "마지막으로 $P_{SVD}^{(0)} = P_*D_*^{1/2}, Q_{SVD}^{(0)} = Q_*D_*^{1/2} $ 로 초기화 시킨다. 실제적으로 P_0, Q_0 은 직교행렬이여야 하는데. \n",
    "초기화 전략은 직교행렬 가정이 없다면\n",
    "최적화 문제 (5)가 다소 부정적이지만 실무적으로는 그냥 써도 된다.\n",
    "\n",
    "ANOVA 모델은 R매트릭스의 missing 값들을 구현하는데 기본적인 모델로 사용 가능하다. 그러나 ANOVA 모델은 MF 하기 전에 노멀라이제이션 했으므로 이걸로 하면 NA 값들이 0 이 되어버린다. 이는 노멀라이제이션 하기 전에 ANOVA로 missing value 채워넣으면 된다.\n",
    "\n",
    "이러한 initialization 들은 BL,AB,gAB,TG에 모두 사용가능 한데 RC 에서는 추가적인 단계가필요하다 RC의 제약조건이 Q = AB이기 때문이다. 가장 자연스러운 방법은 밑에와 같다\n",
    "\n",
    "$B_{SVD}^{(0)} = (A^TA)^{-1}A^TQ_{SVD}^{(0)}$\n",
    "\n",
    "만약 D>M 이면 \n",
    "\n",
    "$B_{SVD}^{(0)} = (A^TA+\\delta I)^{-1}A^TQ_{SVD}^{(0)}$\n",
    "\n",
    "for some \\gamma >0 우리의 선택은 diag(A^TA) 의 median value 였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5.2 Mixed strategy\n",
    "\n",
    "\n",
    "앞에서 말한 SVD 전략은 그 자체로는 실제로 유용하지만, 미묘한 문제가있었습니다\n",
    "비교를 해보면: RC에 상대적 dissadvantage가 있습니다. 이는 만약 P,Q 가 가장 합리적인 initialization 이라고 하면 RC에서의 P,AB 는 그만큼 좋지 않습니다.\n",
    "\n",
    "$AB_{SVD}^{(0)} = A(A^TA)^{-1}A^TQ_{SVD}^{(0)}$\n",
    "\n",
    "이는 단순히 Q의 prjected version 입니다. 모든 알고리즘의 공정한 비교를 위해서 우리는 mixed 전략을 사용했습니다. P는 밑처럼 초기화됩니다.\n",
    "\n",
    "\n",
    "$P^{(0)} = KP^{(0)}_{SVD} + (1-K)P^{(0)}_{RANDOM}$ \n",
    "\n",
    "\n",
    "P_SVD는 SVD 를 통해 얻은 것이고 P_RANDOM 은 N(0,S^2) 에 의해 얻어진 값들 입니다. 같은 과정이 Q,B 초기화에 사용되었습니다. K가 주어진다면 k,S 는 (BL,AB,GAB,TG)와 RC 의 두가지 집합에 다르게 적용 되었고 이를 통해 비교를 할 수 있는 비슷한 성능을 내게 하였습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 The choice of λ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
