{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch3 LEARNING IN PARAMETRIC MODELING: \n",
    "# BASIC CONCEPTS AND DIRECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 PARAMETER ESTIMATION: THE DETERMINISTIC POINT OF VIEW\n",
    "\n",
    "The task of estimating the value of an unknown parameter vector, θ,\n",
    "\n",
    "Parameter estimation - θ 에 관한 어떠한 함수를 만들고 θ 를 추정하는 것\n",
    "\n",
    "<img src=\"picture_ch3/캡처1.png\" width=600 />\n",
    "\n",
    "a 와 b라는 데이터를 추정하기 위해 어떠한 함수를 만들었다\n",
    "\n",
    ">Figure 3.1 a $y = f_θ (x) = θ_0 + θ_1x$ \n",
    "\n",
    ">$θ_∗ = [−0.5, 1]^T$\n",
    "\n",
    ">Figure 3.1 b $y = f_θ (x) = θ_0 + θ_1x + θ_2x^2.$  \n",
    "\n",
    ">$θ_∗ = [−3, -2 ,1]^T$\n",
    "\n",
    "함수의 형태를 결정하는 것은 쉽지 않지만 사전 지식과 데이터의 분포를 고려하여 결정 할 수 있다 운좋게도 우리가 설정한 a와 b의 가설함수와 θ는 얼추 맞는 것 같다.\n",
    "\n",
    "$F$ 에 대한 파라미터를 최적화 하기 위한 접근중 하나는 Loss function 이다. Loss function 은 예측한 x와 y에 대한 편차/에러를 수량화 하여 나타내준다\n",
    "\n",
    "\n",
    "\n",
    ">$f (·) := f_{θ∗} (·) : θ_∗ = arg min_{θ∈A}J(θ),$\n",
    "\n",
    ">$J(θ) := \\sum_{n=1}^{N}L(y_n, f_θ (x_n))$\n",
    "\n",
    ">$L(y, f_θ (x))=(y − f_θ (x))^2$\n",
    "\n",
    "\n",
    "total loss 를 최소화 하는 θ∗ 를 계산하자   \n",
    "J(θ) 는 보통 cost 라고 하며 주어진 데이터에서의 모든 loss 의 합이다  \n",
    "이번 챕터에서는 간단한 LS 를 loss function 으로 사용한다\n",
    "\n",
    "### Cost function\n",
    "\n",
    "loss function은 예측한 x와 y에 대한 편차/에러를 수량화 하여 나타내 준다\n",
    "사용할 수 있는 여러가지 Loss function의 꼴이 있는데 가장 간단하게 사용할 수 있는 책에서는 가장 간단한 LS- (실제값 - 예측값)^2 를 사용했다. 매우 간단고 직관적이다. 이때 제곱을 해준 이유는 편차들의 합이 0되는 경우가 있기 때문이다\n",
    "\n",
    "\n",
    "<img src=\"picture_ch3/캡처8.png\" width=600 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LINEAR REGRESSION\n",
    "\n",
    "에러텀 η을 포함해서 일반화 하여 나타 낼 수 있다.\n",
    "\n",
    "$y = θ_0 + θ_1x_1 +· · ·+θ_lx_l + η = θ_0 + θ^T_x + η.$\n",
    "\n",
    "하지만 η 는 관찰 불가능 하기 때문에 다른 모델을 만들어야 하는데\n",
    "\n",
    "given x 일때의 output y 를 예측하는 모델을 만들었다\n",
    "\n",
    "$\\hat{y} = \\hat{θ_0} + \\hat{θ_1}x1 +· · ·+ \\hat{θ_l}x_l := \\hat{θ}^\n",
    "T\n",
    "x.$\n",
    "\n",
    "\n",
    ">$J(θ) := \\sum_{n=1}^{N}L(y_n, f_θ (x_n))$ \n",
    "\n",
    "J(θ) = 0 으로 두고 θ에 대해 편미분하면\n",
    "θ 의 LS 추정값을 얻을 수 있다.\n",
    "\n",
    "$\\hat{θ}\n",
    "= (X^TX)^\n",
    "{−1}X^T y : The LS Estimate,$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 CLASSIFICATION\n",
    "\n",
    "classfier 의 목적은 decision surface(decision boundary) ,f(x)를 f(x) = 0 으로 만드는 것이다. \n",
    "\n",
    "\n",
    "regression 때와 동일하게 given x 일때의 output y를 예측 하는 모델을 만들었다. \n",
    "\n",
    "$  \\hat{y}= φ(f (x)),$\n",
    "\n",
    "φ() 는 decision surface(decision boundary)의 가장자리를 나타내는 비선형 함수이고 만약 class label 이 +-1 이라면 사인 함수나 sgn() 이 될수 있다.\n",
    "\n",
    "이제 우리의 목표는 파라미터의 추정이다. \n",
    "\n",
    "그러면 classfication과 regression 사이의 다른점이 무엇인가?\n",
    "\n",
    "classfication과 regression은 비슷하지만 다르다. classfication 에서는 종속변수가 이산 변수이고 regression은 연속변수이다. \n",
    "\n",
    "classficaition과 regression 모두 파라미터를 통해 최적화 하지만 다른 기술을 사용한다. 예를들어 classfication 에서는 확률의 에러를 통해 최적화 한다. classfication과 regression 이 같은 loss functions을 사용할 수도 있고 수학적 과정도 유사하지만 두 과제의 목표는 매우 다르다.\n",
    "\n",
    "0,1 의 두가지 클래스를 예측하도록 주어진다면  \n",
    "\n",
    "$f (x) = θ_0 + θ_1x_1 +· · ·+θ_lx_l\n",
    "= θ^Tx = 0,$  \n",
    "위의 함수를 0으로 만드는 것이 목표이다\n",
    "\n",
    "결국 p(y)=f(x)=0 으로 만드는 것이 목표라는 의미\n",
    "<img src=\"https://plot.ly/~florianh/149.png\" width=600 />\n",
    "\n",
    "\n",
    "regression 때와 마찬가지로\n",
    "LS 을 이용하면 cost function은 밑으로 정의한다  \n",
    "$J(θ) := \\sum_{n=1}^{N}(y_n-θ^Tx_n)^2$\n",
    "\n",
    "cost fucntion 을 최적화 하는 θ를 구하면 밑과같은 plot을 얻을 수 있다\n",
    "<img src=\"picture_ch3/캡처2.png\" width=600 />\n",
    "\n",
    "## Example logistic regression\n",
    "\n",
    "f(x) = ax + b= a(x-b)\n",
    "\n",
    " $ g(X) = \\frac { 1 }{1+e^{-a(x-b)}} $\n",
    " \n",
    " \n",
    "<img src=\"http://cvxr.com/cvx/examples/cvxbook/Ch07_statistical_estim/html/logistics__01.png\" width=600 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 BIASED VERSUS UNBIASED ESTIMATION  \n",
    "\n",
    "\n",
    " $(y_n, x_n), n = 1, 2,$의 n개의 데이터를 가지고 어떻게 추정하는지가 중요하다 우리가 얻어낸 추정치가 실제값과 가까운지를 보증하는 것이 필요하다. 이번 장에서 몇가지 추정치들을 살펴 볼 것이다.\n",
    " \n",
    "추정치의 성능을 측정하는 방법중 하나는 MSE(mean squar error)이다\n",
    "\n",
    "θ_o = True Parameter\n",
    "\n",
    "$MSE = E[(\\hat{θ} − θ_o)^2]$\n",
    "\n",
    "\n",
    "$MSE = E[(\\hat{θ} − θ_o)^2] = E[(\\hat{θ} − E[\\hat{θ}])^2]+(E[\\hat{θ}]-θ_o ) = Variance + Bias$  \n",
    ",\n",
    "MSE는 $\\hat{θ}$ 의 Variance와 Bias로 유도된다.\n",
    "\n",
    "\n",
    "## 3.5.1 BIASED OR UNBIASED ESTIMATION?\n",
    "\n",
    "추정량을 선택하는 방법중 하나로 (Unbiased estimator)불편추정량을 생각 할 수 있다. 이것은 위의 Bias 텀을 0 으로 하는 추정치이다. 즉 $E[\\hat{θ}] = θ_o$ \n",
    "\n",
    "### 불편추정량(Unbiased estimator)\n",
    "\n",
    "\n",
    "> $E[\\hat{θ}] = θ_o$ \n",
    "\n",
    "Let us denote each data set by Di, i = 1, 2, . . . , L. For each one, an estimate ˆ θi,\n",
    "i = 1, 2, . . . , L,\n",
    "\n",
    "L개의 데이터(표본)과 L개의 θ가 존재 할때의 불편 추정량은 평균값이다\n",
    "\n",
    "$\\hat{θ}^{(L)} := 1/L\\sum^L_{i=1}\\hat{θ}_i.$\n",
    "\n",
    "\n",
    "\n",
    "### 유효추정량 (efficient estimator)\n",
    "\n",
    "\n",
    "> $E[(\\hat{θ_1} − E[\\hat{θ_1}])^2]<E[(\\hat{θ_2} − E[\\hat{θ_2}])^2]$ \n",
    "\n",
    "θ_1의 분산이 θ_2 보다 작으므로 더 유효한 추정량이라고 한다\n",
    "\n",
    "\n",
    "불편추정량 중에서 더 좋은 추정량을 구하자는 아이디어를 얻을 수 있다. 불편추정량 중에서 가장 유효한 추정량을 구해보자 \n",
    "\n",
    "### 최소 분산 불편추정량 (Minimum Variance Unbiased Esimator)\n",
    "\n",
    "\n",
    "θ_mvu 를 구하기 위해서는 θ: E[θ]=θ_o 인 것들중 가장 작은 분산을 가진 추정치를 구하면 된다\n",
    "\n",
    "MSE = Variance + bias 므로 bias=0 으로 두고 mse를 min하는 과제로 바뀐다\n",
    "\n",
    "$min_{θ: E[θ]=θ_o} MSE(θ).$\n",
    "\n",
    "\n",
    "### (편향 추정량??) biased estimator, which results, hopefully, in a smaller MSE\n",
    "\n",
    "\n",
    "$min_θMSE(θ) ≤ min_{θ: E[θ]}=θ_oMSE(θ),$\n",
    "\n",
    "$\\hat{θ_b} = (1 + a) \\hat{θ}_{MVU},$\n",
    "\n",
    "위의 성질 때문에 $MSE(\\hat{θ_b}) = (1 + α)^2MSE(\\hat{θ_{MVU}}) + α^2θ^2_\n",
    "o$ .\n",
    "\n",
    "로 나타낼 수 있고 a 는 식의 전개과정을 통해 구할 수 있다는게 증명된다\n",
    "\n",
    "\n",
    "결국 ${\\hat{θ_b} = (1 +\n",
    "α)\\hat{θ_{MVU}} : α ∈ R}$ 로 MVU로 biased estimator 까지 구할수 있다.\n",
    "\n",
    "이런 이유 때문에 mvu 가 중요하다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 THE CRAMÉR-RAO LOWER BOUND\n",
    "\n",
    "이전의 세션에서 우리는 MVU esimator를 향상시키는 방법을 보았다. 그렇다면 MVU esimator를 알수 있는 방법이 무엇이 있을까??\n",
    "\n",
    "Craomer-Rao lower bountd 는 불편추정량를 구하기 위한 좋은 방법중 하나이다. CRLB 를 통해 어떤(ANY) 불편추정량의 분산의 하한을 알 수 있다.\n",
    "\n",
    "이것은 매우 중요한데\n",
    "\n",
    "- CRLB은 불편추정치가 최소의 분산을 가진다는 것을 의미한다.\n",
    "- CRLB을 구하지 못한다해도 이것은 우리가 구한 추정치가 CRLB와 얼마나 떨어져있는지를 통해 추정치를 평가 가능하다\n",
    "- CRLB을 통해 우리가 불편추정치를 통해 어디까지 성능향상이 가능한지 판단가능하다\n",
    "\n",
    "<img src=\"picture_ch3/캡처7.png\" width=600 />\n",
    "\n",
    "결국 CRLB를 통해서 MVU를 쉽게 구할 수 있다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 SUFFICIENT STATISTIC\n",
    "\n",
    "만약 라오크래머 하한을 통해 구해지는 값이 없다면 이것이 MVU를 구할수 없다는 뜻이 아니다. 단지 라오크래머 하한을 만족하지 않는 것이다. 더나아가 라오 블랙웰 정리를 사용하여 MVU 를 구할 수 있다.\n",
    "\n",
    "### 충분통계량 (Sufficient statistic)\n",
    "\n",
    "$T(X) := T(x_1, x_2, . . . , x_N),$ 만약 어떤 통계량 T(X)가 존재할때  \n",
    "$p (X|T(X); θ) ,$ 이런 conditional joint pdf가 θ에 의존적이지 않다면 T(X)는 충분통계량이다.\n",
    "\n",
    "T(X)가 충분통계량 이라는의미는 T(X)가 θ에 대한 정보를 충분히 가지고 있다는 것이다.\n",
    "\n",
    "이는 네이만의 인수분해 정리에 의해 밑처럼 표현될 수 있다.  \n",
    "$p(X; θ) = h(X)g (T(X), θ) .$ \n",
    "\n",
    "이 의미는 joint pdf 가 두가지 부분으로 나누어 진다는 것인데 θ에 독립적인 h(X) 라는 부분과 g (T(X), θ) 의 부분으로 나누어 진다는 것이다. \n",
    "\n",
    "이를 라오-블랙웰 정리를 통해 MVUE를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 REGULARIZATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 THE BIAS-VARIANCE DILEMMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 MAXIMUM LIKELIHOOD METHOD\n",
    "\n",
    "\n",
    "N개의 X={x1,x2,x3,,,,xn} 의 관측값이 있을때 \n",
    "\n",
    "x들의 결합분포(joint pdf) 는 p(X:θ) 이고 이것을  θ 에 대한Likelihood function 라고 한다.\n",
    "\n",
    "이 Likelihood function을 최대로 하는 θ를 Likelihood estimation 이라고 한다\n",
    "\n",
    "<img src=\"picture_ch3/캡처3.png\" width=600 />\n",
    "\n",
    "<img src=\"picture_ch3/캡처4.png\" width=600 />\n",
    "<img src=\"picture_ch3/캡처6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 BAYESIAN INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 CURSE OF DIMENSIONALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 EXPECTED AND EMPIRICAL LOSS FUNCTIONS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
