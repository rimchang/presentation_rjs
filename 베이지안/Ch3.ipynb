{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch3 LEARNING IN PARAMETRIC MODELING: \n",
    "# BASIC CONCEPTS AND DIRECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 PARAMETER ESTIMATION: THE DETERMINISTIC POINT OF VIEW\n",
    "\n",
    "The task of estimating the value of an unknown parameter vector, θ,\n",
    "\n",
    "Parameter estimation - θ 에 관한 어떠한 함수를 만들고 θ 를 추정하는 것\n",
    "\n",
    "<img src=\"./picture_ch3/캡처1.png\" width=600 />\n",
    "\n",
    "a 와 b라는 데이터를 추정하기 위해 어떠한 함수를 만들었다\n",
    "\n",
    ">Figure 3.1 a $y = f_θ (x) = θ_0 + θ_1x$ \n",
    "\n",
    ">$θ_∗ = [−0.5, 1]^T$\n",
    "\n",
    ">Figure 3.1 b $y = f_θ (x) = θ_0 + θ_1x + θ_2x^2.$  \n",
    "\n",
    ">$θ_∗ = [−3, -2 ,1]^T$\n",
    "\n",
    "함수의 형태를 결정하는 것은 쉽지 않지만 사전 지식과 데이터의 분포를 고려하여 결정 할 수 있다 운좋게도 우리가 설정한 a와 b의 가설함수와 θ는 얼추 맞는 것 같다.\n",
    "\n",
    "$F$ 에 대한 파라미터를 최적화 하기 위한 접근중 하나는 Loss function 이다. Loss function 은 예측한 x와 y에 대한 편차/에러를 수량화 하여 나타내준다\n",
    "\n",
    "\n",
    "\n",
    ">$f (·) := f_{θ∗} (·) : θ_∗ = arg min_{θ∈A}J(θ),$\n",
    "\n",
    ">$J(θ) := \\sum_{n=1}^{N}L(y_n, f_θ (x_n))$\n",
    "\n",
    ">$L(y, f_θ (x))=(y − f_θ (x))^2$\n",
    "\n",
    "\n",
    "total loss 를 최소화 하는 θ∗ 를 계산하자   \n",
    "J(θ) 는 보통 cost 라고 하며 주어진 데이터에서의 모든 loss 의 합이다  \n",
    "이번 챕터에서는 간단한 LS 를 loss function 으로 사용한다\n",
    "\n",
    "### Cost function\n",
    "\n",
    "loss function은 예측한 x와 y에 대한 편차/에러를 수량화 하여 나타내 준다\n",
    "사용할 수 있는 여러가지 Loss function의 꼴이 있는데 가장 간단하게 사용할 수 있는 책에서는 가장 간단한 LS- (실제값 - 예측값)^2 를 사용했다. 매우 간단고 직관적이다. 이때 제곱을 해준 이유는 편차들의 합이 0되는 경우가 있기 때문이다\n",
    "\n",
    "\n",
    "<img src=\"picture_ch3/캡처8.png\" width=600 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LINEAR REGRESSION\n",
    "\n",
    "에러텀 η을 포함해서 일반화 하여 나타 낼 수 있다.\n",
    "\n",
    "$y = θ_0 + θ_1x_1 +· · ·+θ_lx_l + η = θ_0 + θ^T_x + η.$\n",
    "\n",
    "하지만 η 는 관찰 불가능 하기 때문에 다른 모델을 만들어야 하는데\n",
    "\n",
    "given x 일때의 output y 를 예측하는 모델을 만들었다\n",
    "\n",
    "$\\hat{y} = \\hat{θ_0} + \\hat{θ_1}x1 +· · ·+ \\hat{θ_l}x_l := \\hat{θ}^\n",
    "T\n",
    "x.$\n",
    "\n",
    "\n",
    ">$J(θ) := \\sum_{n=1}^{N}L(y_n, f_θ (x_n))$ \n",
    "\n",
    "J(θ) = 0 으로 두고 θ에 대해 편미분하면\n",
    "θ 의 LS 추정값을 얻을 수 있다.\n",
    "\n",
    "$\\hat{θ}\n",
    "= (X^TX)^\n",
    "{−1}X^T y : The LS Estimate,$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 CLASSIFICATION\n",
    "\n",
    "classfier 의 목적은 decision surface(decision boundary) ,f(x)를 f(x) = 0 으로 만드는 것이다. \n",
    "\n",
    "\n",
    "regression 때와 동일하게 given x 일때의 output y를 예측 하는 모델을 만들었다. \n",
    "\n",
    "$  \\hat{y}= φ(f (x)),$\n",
    "\n",
    "φ() 는 decision surface(decision boundary)의 가장자리를 나타내는 비선형 함수이고 만약 class label 이 +-1 이라면 사인 함수나 sgn() 이 될수 있다.\n",
    "\n",
    "이제 우리의 목표는 파라미터의 추정이다. \n",
    "\n",
    "그러면 classfication과 regression 사이의 다른점이 무엇인가?\n",
    "\n",
    "classfication과 regression은 비슷하지만 다르다. classfication 에서는 종속변수가 이산 변수이고 regression은 연속변수이다. \n",
    "\n",
    "classficaition과 regression 모두 파라미터를 통해 최적화 하지만 다른 기술을 사용한다. 예를들어 classfication 에서는 확률의 에러를 통해 최적화 한다. classfication과 regression 이 같은 loss functions을 사용할 수도 있고 수학적 과정도 유사하지만 두 과제의 목표는 매우 다르다.\n",
    "\n",
    "0,1 의 두가지 클래스를 예측하도록 주어진다면  \n",
    "\n",
    "$f (x) = θ_0 + θ_1x_1 +· · ·+θ_lx_l\n",
    "= θ^Tx = 0,$  \n",
    "위의 함수를 0으로 만드는 것이 목표이다\n",
    "\n",
    "결국 p(y)=f(x)=0 으로 만드는 것이 목표라는 의미\n",
    "<img src=\"https://plot.ly/~florianh/149.png\" width=600 />\n",
    "\n",
    "\n",
    "regression 때와 마찬가지로\n",
    "LS 을 이용하면 cost function은 밑으로 정의한다  \n",
    "$J(θ) := \\sum_{n=1}^{N}(y_n-θ^Tx_n)^2$\n",
    "\n",
    "cost fucntion 을 최적화 하는 θ를 구하면 밑과같은 plot을 얻을 수 있다\n",
    "<img src=\"picture_ch3/캡처2.png\" width=600 />\n",
    "\n",
    "## Example logistic regression\n",
    "\n",
    "f(x) = ax + b= a(x-b)\n",
    "\n",
    " $ g(X) = \\frac { 1 }{1+e^{-a(x-b)}} $\n",
    " \n",
    " \n",
    "<img src=\"http://cvxr.com/cvx/examples/cvxbook/Ch07_statistical_estim/html/logistics__01.png\" width=600 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추정의 몇가지 방법들\n",
    "\n",
    "Linear regression의 θ 추정의 몇가지 방법들\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 1,점추정\n",
    "    - min MSE 추정 - 아무런 제약없이 MSE를 최소화 하는 추정량\n",
    "    - MVU 추정 - 불편추정량 이라는 제약 하에 MSE를 최소화\n",
    "    - 등등등\n",
    "    \n",
    "    \n",
    "$P(θ|X)=\\frac{P(X|θ)P(θ)}{P(X)}$ $=\\frac{𝑳𝒊𝒌𝒆𝒍𝒊𝒉𝒐𝒐𝒅 * 𝑷𝒓𝒊𝒐𝒓𝑲𝒏𝒐𝒘𝒍𝒆𝒅𝒈𝒆}{ 𝑵𝒐𝒓𝒎𝒂𝒍𝒊𝒛𝒊𝒏𝒈𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕}$\n",
    "\n",
    "- 2, MLE 추정\n",
    "    \n",
    "    - 우도함수를 최대화 시키는 추정량\n",
    "    <img src=\"picture_ch3/캡처11.png\" width=600 />\n",
    "    \n",
    "- 3, MAP 추정\n",
    "\n",
    "    - 우도함수에 사전확률까지 고려한 사후확률을 최대화 시키는 추정량\n",
    "    <img src=\"picture_ch3/캡처10.png\" width=600 />\n",
    "- 4, 베이지안 추정\n",
    "\n",
    "    - θ 또한 확률변수라고 생각!\n",
    "\n",
    "http://sanghyukchun.github.io/58/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 BIASED VERSUS UNBIASED ESTIMATION  \n",
    "\n",
    "\n",
    " $(y_n, x_n), n = 1, 2,$의 n개의 데이터를 가지고 어떻게 추정하는지가 중요하다 우리가 얻어낸 추정치가 실제값과 가까운지를 보증하는 것이 필요하다. 이번 장에서 몇가지 추정치들을 살펴 볼 것이다.\n",
    " \n",
    "추정치의 성능을 측정하는 방법중 하나는 MSE(mean squar error)이다\n",
    "\n",
    "θ_o = True Parameter\n",
    "\n",
    "$MSE = E[(\\hat{θ} − θ_o)^2]$\n",
    "\n",
    "\n",
    "$MSE = E[(\\hat{θ} − θ_o)^2] = E[(\\hat{θ} − E[\\hat{θ}])^2]+(E[\\hat{θ}]-θ_o ) = Variance + Bias$  \n",
    ",\n",
    "MSE는 $\\hat{θ}$ 의 Variance와 Bias로 유도된다.\n",
    "\n",
    "\n",
    "## 3.5.1 BIASED OR UNBIASED ESTIMATION?\n",
    "\n",
    "추정량을 선택하는 방법중 하나로 (Unbiased estimator)불편추정량을 생각 할 수 있다. 이것은 위의 Bias 텀을 0 으로 하는 추정치이다. 즉 $E[\\hat{θ}] = θ_o$ \n",
    "\n",
    "### 불편추정량(Unbiased estimator)\n",
    "\n",
    "\n",
    "> $E[\\hat{θ}] = θ_o$ \n",
    "\n",
    "Let us denote each data set by Di, i = 1, 2, . . . , L. For each one, an estimate ˆ θi,\n",
    "i = 1, 2, . . . , L,\n",
    "\n",
    "L개의 데이터(표본)과 L개의 θ가 존재 할때의 불편 추정량은 평균값이다\n",
    "\n",
    "$\\hat{θ}^{(L)} := 1/L\\sum^L_{i=1}\\hat{θ}_i.$\n",
    "\n",
    "\n",
    "\n",
    "### 유효추정량 (efficient estimator)\n",
    "\n",
    "\n",
    "> $E[(\\hat{θ_1} − E[\\hat{θ_1}])^2]<E[(\\hat{θ_2} − E[\\hat{θ_2}])^2]$ \n",
    "\n",
    "θ_1의 분산이 θ_2 보다 작으므로 더 유효한 추정량이라고 한다\n",
    "\n",
    "\n",
    "불편추정량 중에서 더 좋은 추정량을 구하자는 아이디어를 얻을 수 있다. 불편추정량 중에서 가장 유효한 추정량을 구해보자 \n",
    "\n",
    "### 최소 분산 불편추정량 (Minimum Variance Unbiased Esimator)\n",
    "\n",
    "\n",
    "θ_mvu 를 구하기 위해서는 θ: E[θ]=θ_o 인 것들중 가장 작은 분산을 가진 추정치를 구하면 된다\n",
    "\n",
    "MSE = Variance + bias 므로 bias=0 으로 두고 mse를 min하는 과제로 바뀐다\n",
    "\n",
    "$min_{θ: E[θ]=θ_o} MSE(θ).$\n",
    "\n",
    "\n",
    "### (편향 추정량??) biased estimator, which results, hopefully, in a smaller MSE\n",
    "\n",
    "\n",
    "$min_θMSE(θ) ≤ min_{θ: E[θ]}=θ_oMSE(θ),$\n",
    "\n",
    "$\\hat{θ_b} = (1 + a) \\hat{θ}_{MVU},$\n",
    "\n",
    "위의 성질 때문에 $MSE(\\hat{θ_b}) = (1 + α)^2MSE(\\hat{θ_{MVU}}) + α^2θ^2_\n",
    "o$ .\n",
    "\n",
    "로 나타낼 수 있고 a 는 식의 전개과정을 통해 구할 수 있다는게 증명된다\n",
    "\n",
    "\n",
    "결국 ${\\hat{θ_b} = (1 +\n",
    "α)\\hat{θ_{MVU}} : α ∈ R}$ 로 MVU로 biased estimator 까지 구할수 있다.\n",
    "\n",
    "이런 이유 때문에 mvu 가 중요하다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 THE CRAMÉR-RAO LOWER BOUND\n",
    "\n",
    "이전의 세션에서 우리는 MVU esimator를 향상시키는 방법을 보았다. 그렇다면 MVU esimator를 알수 있는 방법이 무엇이 있을까??\n",
    "\n",
    "Craomer-Rao lower bountd 는 불편추정량를 구하기 위한 좋은 방법중 하나이다. CRLB 를 통해 어떤(ANY) 불편추정량의 분산의 하한을 알 수 있다.\n",
    "\n",
    "이것은 매우 중요한데\n",
    "\n",
    "- CRLB은 불편추정치가 최소의 분산을 가진다는 것을 의미한다.\n",
    "- CRLB을 구하지 못한다해도 이것은 우리가 구한 추정치가 CRLB와 얼마나 떨어져있는지를 통해 추정치를 평가 가능하다\n",
    "- CRLB을 통해 우리가 불편추정치를 통해 어디까지 성능향상이 가능한지 판단가능하다\n",
    "\n",
    "<img src=\"picture_ch3/캡처7.png\" width=600 />\n",
    "\n",
    "결국 CRLB를 통해서 MVU를 쉽게 구할 수 있다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 SUFFICIENT STATISTIC\n",
    "\n",
    "만약 라오크래머 하한을 통해 구해지는 값이 없다면 이것이 MVU를 구할수 없다는 뜻이 아니다. 단지 라오크래머 하한을 만족하지 않는 것이다. 더나아가 라오 블랙웰 정리를 사용하여 MVU 를 구할 수 있다.\n",
    "\n",
    "### 충분통계량 (Sufficient statistic)\n",
    "\n",
    "$T(X) := T(x_1, x_2, . . . , x_N),$ 만약 어떤 통계량 T(X)가 존재할때  \n",
    "$p (X|T(X); θ) ,$ 이런 conditional joint pdf가 θ에 의존적이지 않다면 T(X)는 충분통계량이다.\n",
    "\n",
    "T(X)가 충분통계량 이라는의미는 T(X)가 θ에 대한 정보를 충분히 가지고 있다는 것이다.\n",
    "\n",
    "이는 네이만의 인수분해 정리에 의해 밑처럼 표현될 수 있다.  \n",
    "$p(X; θ) = h(X)g (T(X), θ) .$ \n",
    "\n",
    "이 의미는 joint pdf 가 두가지 부분으로 나누어 진다는 것인데 θ에 독립적인 h(X) 라는 부분과 g (T(X), θ) 의 부분으로 나누어 진다는 것이다. \n",
    "\n",
    "이를 라오-블랙웰 정리를 통해 MVU를 구할 수 있다.\n",
    "\n",
    "http://m.blog.naver.com/s2ak74/220615638009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 REGULARIZATION\n",
    "\n",
    "Regulariztion은 θ에 대한 사전정보를 부여하여 overfitting을 피하는 방법이다. \n",
    "\n",
    "이전에 LS estmator를 이용하여 cost 함수를 정의했었다.  \n",
    "\n",
    "minimize : $J(θ) := \\sum_{n=1}^{N}(y_n-θ^Tx_n)^2$\n",
    "\n",
    "가정을 추가 : ${||θ||}^2 ≤ ρ$,\n",
    "\n",
    "$||θ||$ 은 벡터의 euclidean norm 을 나타낸다. 이 방법을 통해 우리는 LS 가 완전히 자유롭지 않게 한다. 우리는 θ의 공간을 한정한다. 다른 P 값을 사용함으로써 다른 level의 shrinkage을 얻을 수 있다. optimal value 인 p는 분석적으로 얻어지는 것이 아닌 실험을 CV등의 많은 실험을 통해 얻을 수 있다.. \n",
    "\n",
    "위의 두식을 합치면 밑과 같은 loss fuction을 얻을 수 있다.\n",
    "\n",
    "minimize: $L(θ, λ) =\\sum^N_{n=1}(y_n − θ^Tx_n)^2+ λ{||θ||}^2 : Ridge Regression.$\n",
    "\n",
    "λ ≥ 0 and ρ, 에서의 두 과제는 같다.( ${\\frac{1}{p}||θ||}^2 ≤ 1$ 이니까??)새로운 cost fuction $L(θ, λ)$ 을 살펴보면 misfit 과 θ의 size의 두텀으로 나뉘어 지는 것을 알 수있다. 이를 이전 과 같이 $L(θ, λ)=0$ 으로 두고 θ 값을 구하면 θ을 구할 수 있다.\n",
    "\n",
    "이런 regression 을 ridge regression 이라고 한다. 결국 이 모델의 목적은 θ의 크기를 줄임과 동시에 sum of squared error를 줄여나가는 것이다. CH6 에서 더 자세히알아 볼것이다\n",
    "\n",
    "이번 장에서 강조할 것은 the bias parameter, $\\hat{θ_0}$, 인데 이것은 보통 정규화 텀에서 빠진다. \n",
    "\n",
    "<img src=\"picture_ch3/캡처12.png\" width=600 />\n",
    "\n",
    "다른 말로 하면 $\\hat{θ_0}$ 은 compensates for the differences between the sample means of the output and input variables.해준다..?\n",
    "\n",
    "### Inverse problems: Ill-conditioning and overfitting\n",
    "\n",
    "대부분의 머신러닝은 **inverse problems ** 을 가진다. \n",
    "\n",
    "**inverse problems **\n",
    "\n",
    "'물체는 고유한 진동을 지니고 있는데, 이를 '스펙트럼'이라고 한다\n",
    "거꾸로 스펙트럼을 알아 그것이 어떤 사물에서 나온 것인지  알 수 있다면 사물과 스펙트럼은 같은 것이라고 할 수 있다. 과학자들이 멀리있는 별이 내는 빛을 보고 별의 성분이나 운동을 밝히는 것도 이러한 '거꿀 생각'을 활용한 것이다.\n",
    " \n",
    "의사들이 청진기를 이용하여 환자의 심장이나 폐의 소리를 듣고 이로부터 병을 진단해내는 것도 '거꿀생각'을 활용하는 것이다.\n",
    " \n",
    "이는 마치 북소리를 듣고, 그 북이 어떻게 생겼는지 알 수 있느냐는 질문과 같은 것으로 이와같은 문제를  <Inverse Problem> -역문제- 라고 부른다.\"\n",
    "[출처] Inverse Problem|작성자 꿈꾸는 사람\n",
    "\n",
    "이런 inverse prolem은 전형적으로 ill-posed 이고 regularzation은 이런 ill-posed 를 해결하는데 적합하다\n",
    "\n",
    "> *ill-posed*\n",
    ">- 해가 존재하지않고\n",
    ">- 유일한 해 x\n",
    ">- 많은 θ 공간이 존재 \n",
    ">- overfitting \n",
    "\n",
    "> *well_posed*\n",
    "> - 해가 존재하고 \n",
    "> - 해가 유일하고 \n",
    "> - The solution depends continuously on the data, in some reasonable topology  \n",
    "    즉 얻어지는 솔루션이 트레이닝 셋의 변화에 매우 민감하다\n",
    "    \n",
    "    \n",
    "만약 θ의 갯수에 비해 많은 training 샘플이 존재한다면 이런 데이터로는 좋은 모델을 만들 수 없다. 노이즈와 outlier에 의해 잘못된 모델이 만들어 질 것이다. regulariztion 은 이런 문제를 가지는 모델에 좋은 해결방안이 된다. \n",
    "\n",
    "example) 100개의 training sample일때 θ가 300개 라면 수학적으로 해를 구할 수 없다. regularization을 사용하면 해를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 THE BIAS-VARIANCE DILEMMA\n",
    "\n",
    "The first question to be addressed is whether there exists an estimator that guarantees minimum MSE performance.\n",
    "\n",
    "이전에서 했던 것들은 unknown parameter 찾는 것이였다면 unknown estimator를 찾는 과제로 바꾸어보자\n",
    "\n",
    "our goal becomes to obtain\n",
    "an estimator of the value y, given a measurement of the regressor vector, x = x. Let us first consider\n",
    "the more general form of regression,\n",
    "\n",
    "$y = g(x) + η,$\n",
    "\n",
    "\n",
    "### MEAN-SQUARE ERROR ESTIMATION\n",
    "\n",
    "이제 우리의 목표는 unknown(nonlinear in general) function g(x)의 추정인 $\\hat{g(x)}$ 를 찾는 것이다\n",
    "\n",
    "<img src=\"picture_ch3/캡처13.png\" width=500 />\n",
    "\n",
    "\n",
    "### BIAS-VARIANCE TRADEOFF\n",
    "\n",
    "\n",
    "역시 estimator을 평가하는 좋은 방법중의 하나는 MSE 이다.\n",
    "\n",
    "unknown estimator의 MSE\n",
    "\n",
    "<img src=\"picture_ch3/캡처14.png\" width=300 />\n",
    "\n",
    ">이전에 봤던 unknown parameter의 MSE\n",
    "\n",
    ">$MSE = E[(\\hat{θ} − θ_o)^2] = E[(\\hat{θ} − E[\\hat{θ}])^2]+(E[\\hat{θ}]-θ_o ) = Variance + Bias$  \n",
    "\n",
    "\n",
    "<img src=\"https://maikolsolis.files.wordpress.com/2011/11/hist_mise.png\" width=300 /><img src=\"http://i.stack.imgur.com/alkeM.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 MAXIMUM LIKELIHOOD METHOD\n",
    "\n",
    "\n",
    "N개의 X={x1,x2,x3,,,,xn} 의 관측값이 있을때 \n",
    "\n",
    "x들의 결합분포(joint pdf) 는 p(X:θ) 이고 이것을  θ 에 대한Likelihood function 라고 한다.\n",
    "\n",
    "이 Likelihood function을 최대로 하는 θ를 Likelihood estimation 이라고 한다\n",
    "\n",
    "$P(θ|X)=\\frac{P(X|θ)P(θ)}{P(X)}$ $=\\frac{𝑳𝒊𝒌𝒆𝒍𝒊𝒉𝒐𝒐𝒅 * 𝑷𝒓𝒊𝒐𝒓𝑲𝒏𝒐𝒘𝒍𝒆𝒅𝒈𝒆}{ 𝑵𝒐𝒓𝒎𝒂𝒍𝒊𝒛𝒊𝒏𝒈𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕}$    \n",
    "\n",
    "우도함수란?\n",
    "\n",
    ">통계학에서, 가능도(可能度, 영어: likelihood) 또는 우도(尤度)는 확률 분포의 모수가, 어떤 확률변수의 표집값과 일관되는 정도를 나타내는 값이다. 구체적으로, 주어진 표집값에 대한 모수의 가능도는 이 모수를 따르는 분포가 주어진 관측값에 대하여 부여하는 확률이다. 가능도 함수는 확률 분포가 아니며, 합하여 1이 되지 않을 수 있다.\n",
    "\n",
    ">EX) 동전던지기를 100회 시행해서 56번의 앞면이라는 데이터를 가지고 있다.  \n",
    "\n",
    ">동전던지기가 이항분포를 따를 것은 알고있다. \n",
    "\n",
    ">우리가 궁금한건 $P(θ|X)=\\frac{P(X|θ)P(θ)}{P(X)}$ $=\\frac{𝑳𝒊𝒌𝒆𝒍𝒊𝒉𝒐𝒐𝒅 * 𝑷𝒓𝒊𝒐𝒓𝑲𝒏𝒐𝒘𝒍𝒆𝒅𝒈𝒆}{ 𝑵𝒐𝒓𝒎𝒂𝒍𝒊𝒛𝒊𝒏𝒈𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕}$   \n",
    "\n",
    ">P(X|θ) 는 우리가 이미 알고 있음... 동전던지기 예에서 앞면이 나올 확률이 1/2, 1/3 일때 다 구할 수 있음 - 이항분포..\n",
    "\n",
    ">이때 LIKELIHOOD 는 $P(X|θ)=Likelihood = \\frac{100!}{56!44!}θ^{56}θ^{44}$  즉 θ만 변수로 가지는 함수이다.. x는 알고있다.\n",
    "\n",
    ">결국 likelihood는 θ에 따라 주어진 데이터가 될만한 가능성을 나타낸다..\n",
    "\n",
    ">X라는 데이터를 가지고 있는데 θ에 따라 X라는 데이터가 나올 확률\n",
    "\n",
    "<img src=\"http://www.sciencemag.org/site/feature/data/phylo/coin/Image5.gif\" width=600 />\n",
    "\n",
    "<img src=\"picture_ch3/캡처3.png\" width=600 />\n",
    "\n",
    "<img src=\"picture_ch3/캡처4.png\" width=600 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 BAYESIAN INFERENCE\n",
    "\n",
    "지금까지 우리는 parameter 가 우리가 알지 못하는 어떠한 상수라는 가정을 하였다. bayesian inference 에서는 이 parameter 까지 어떠한 random variable로 생각한다. 이제 우리의 목표는 parameter의 분포를 알아 보는 것이다. \n",
    "\n",
    "Given two jointly distributed random vectors, say, x, θ, Bayes\n",
    "theorem states that\n",
    "\n",
    "\n",
    "기본 베이즈 정리\n",
    "\n",
    "$p(x, θ) = p(x|θ)p(θ) = p(θ|x)p(x).$\n",
    "\n",
    ">WHY??\n",
    ">조건부 확률의 정의...\n",
    ">$p(x|θ) = \\frac{p(x,θ)}{p(θ)}$\n",
    "\n",
    "\n",
    ">우리가 많이 보던것\n",
    "\n",
    ">$P(θ|x)=\\frac{p(θ)p(x|θ)}{p(x)}$ 이거랑 결국 똑같은 소리!!\n",
    "\n",
    "\n",
    "Let X = {xn ∈ Rl, n =1, 2, . . . ,N}, 이고 θ도 random vectors 라고 생각하면\n",
    "\n",
    "$p(θ|X) =\\frac{p(X|θ)p(θ)}{p(X)}=\\frac{p(X|θ)p(θ)}{\\int p(x,θ)dθ}= \\frac{p(X|θ)p(θ)}{\\int p(X|θ)p(θ)dθ}.$ 결국 $\\frac{𝑳𝒊𝒌𝒆𝒍𝒊𝒉𝒐𝒐𝒅 * 𝑷𝒓𝒊𝒐𝒓𝑲𝒏𝒐𝒘𝒍𝒆𝒅𝒈𝒆}{ 𝑵𝒐𝒓𝒎𝒂𝒍𝒊𝒛𝒊𝒏𝒈𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕}$\n",
    "\n",
    "> marginal distribution\n",
    "> $p(x,θ) = \\int p(x,θ)dθ$\n",
    "\n",
    "각각의 관측값들이 독립이라는 가정을 추가하면\n",
    "\n",
    "$p(x|θ)=\\prod_{n=1}^N P(x_n|θ)$ = 사전분포\n",
    "\n",
    "사전분포 p(θ) 는 것은 우리의 사전 지식을 요약하여 나타낸 어떠한 믿음이다. θ에 대한 불확실성은 관측치가 늘어남에 따라 완화 된다. 만약 모델의 가정(사전분포,등등등)들이 합리적이라면 우리는 사후 분포가 실제 θ를 잘 설명한다고 기대할 수 있다. \n",
    "\n",
    "우리의 첫번재 목표는 파라미터 θ 를 추정하는 것이다. \n",
    "\n",
    "첫번째 접근은 MSE opiaml estimate θ이다\n",
    "\n",
    "$\\hat{θ}= E[θ|X] =\\intθp(θ|X) dθ.$\n",
    "\n",
    "베이즈 이론에서 나올 수 있는 다른 접근은 context of statistical\n",
    "inference, 이다 이것은 estimate x given observations $\\textit{X(Data)}$의 분포를 추정한다\n",
    "\n",
    "$p(x|\\textit{X(D)}) =p(x|θ)p(θ|\\textit{X(D)})dθ$\n",
    "\n",
    "x와 X(D) 가 독립이고 given θ 라면 $p(x|X, θ) = p(x|θ),$ 으로 표현할 수 있다. 이 수식을 많이 사용할 것이다. \n",
    "\n",
    "$p(x|\\textit{X(D)})$ 을 구하면 이것을 예측에 사용할 수 있다. x1, . . . , xN,의 데이터가 주어져 있다고 가정하면 n+1 번째의 데이터는 $p(x_{n+1}|\\textit{X(D)})$ 을 통해 알 수 있다. 모든 n번째의 데이터에 대해 알 수 있으므로 underlying randomness is removed 된다\n",
    "\n",
    "새로운 데이터 x_new 를 가지고 regression 을하고 싶다면 p(y|x_new,θ,X(D),,등등등)을 통해 가능하다\n",
    "\n",
    "Example 3.6\n",
    "\n",
    "$y = θ_0 + θ_1x  + η.$  에서 노이즈 η가 독립이라고 가정하면  η ~ N(0,σ^2) 이다.\n",
    "\n",
    "우리는 θ가 정규분포를 따를것이라는 가정을 할 수 있다. \n",
    "$p(θ) = N(θ_0, σ^2_0 ).$ - 사전믿음을 설정하는 작업\n",
    "\n",
    "θ에 대한 가정을 한 후에 다음 목표는 posteriori pdf 를 얻는 것이다.\n",
    "\n",
    "그 다음 measurements y = [y1, . . . , yN]T 라고 하면 E[θ|y] 를 추정할 것이다 - mse를 베이지안으로 추정\n",
    "\n",
    ">우리가 구하고 싶은 사후분포  - 우리의 목표\n",
    ">$p(θ|X) =\\frac{p(X|θ)p(θ)}{p(X)}$=$\\frac{𝑳𝒊𝒌𝒆𝒍𝒊𝒉𝒐𝒐𝒅 * 𝑷𝒓𝒊𝒐𝒓𝑲𝒏𝒐𝒘𝒍𝒆𝒅𝒈𝒆}{ 𝑵𝒐𝒓𝒎𝒂𝒍𝒊𝒛𝒊𝒏𝒈𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕}$\n",
    "\n",
    ">$p(θ) = N(θ_0, σ^2_0 ).$ 이라는 사전믿음을 설정했다.  \n",
    ">$f(x\\;|\\;\\mu ,\\sigma ^{2})={\\frac {1}{\\sqrt {2\\sigma ^{2}\\pi }}}\\;e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}$\n",
    "\n",
    ">일반적인 regression일때의 회귀직선. 여러가정들....ηi ~ N(0,σ^2)  \n",
    ">$p(Y_i|θ)$ ~ $N(θ,σ^2_η)$\n",
    "\n",
    "\n",
    "<img src=\"picture_ch3/캡처17.png\" width=600 />\n",
    "\n",
    "결국 사전분포와 likelihood 가 가우시안이면 사후분포도 가우시안이다. \n",
    "\n",
    "### 3.11.1 THE MAXIMUM A POSTERIORI PROBABILITY ESTIMATION METHOD\n",
    "\n",
    "<img src=\"picture_ch3/캡처18.png\" width=600 />\n",
    "\n",
    "MAP estimate 는 regularized LS solution과 매우 비슷한데$ λ = σ^2_η /σ^ 2_0 $ 인 regularization 이라고 이해 가능하다. 하지만 MAP 도 사전분포가 가진 문제점들이 있다.\n",
    "\n",
    "- 지금까지 배운 ML, MAP , Bayesian estimator는 asymptotically(점근적인) 결과를 낸다 즉 N이 무한대라면 같은 추정을 하는 것이다 . \n",
    "- 베이지안 에서의 사전분포 선택은 매우 힘들다. 위에서 살펴봤듯이 특정 분포의 LIKELIHOOD일때 사전분포로 사용하면 LIKELIHOOD 와 같은 분포가 나오는 사전분포를 conjugate prior라고 한다.\n",
    "- 가우시안분포를 매우 재밌는 성질을 가지고 있다\n",
    "    - 가우시안의 conjugate prior는 가우시안이다..\n",
    "    - jointly pdf도 가우시안 marginal pdf 도 가우시안이다\n",
    "    - jointly gaussian variable의 선형결합도 가우시안이다.\n",
    "    - 중심극한정리에 따르면 sum of a large number of independent random variables 은 가우시안을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 CURSE OF DIMENSIONALITY\n",
    "\n",
    "http://blog.naver.com/wjddudwo209/80212077742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 EXPECTED AND EMPIRICAL LOSS FUNCTIONS\n",
    "\n",
    "우리가 이전에 다루었던 트레이닝 set을 베이스로 estimator를 추정하는 것을 일반화 할 수 있는데 이것을 expected loss 라고 한다. L(·, ·),라는 loss fucntion 이 있고 y^ = f (x) 의 예측한 데이터가 있다면 expected loss는 밑의 식이다\n",
    "\n",
    "loss function을 일반화한 expected loss function\n",
    "\n",
    "$J(f) := E[L(y,f(x)]$ \n",
    "\n",
    "좀더 명확하게 나타내면\n",
    "\n",
    "$J(f ) =\\int{...{\\int L(y, f (x)) p(y, x)dydx}} : Expected Loss Function,$\n",
    "\n",
    ">$E[X]=\\int{Xp(x)}dx$\n",
    "\n",
    "각각의 x가 이산이라고 한다면 \n",
    "\n",
    "$J_N(f ) = \\frac{1}{N}\\sum^N_{n=1}L(y_n, f (x_n): Empirical Loss Function.$\n",
    "\n",
    "하지만 실제로는 하나의 모델이 이산,연속형 변수를 가지는 경우가 많다. 이런 경우 일반화 하기가 어려운데 F라는 certain family functions 집합으로 표현하는 방법, 더 다루기 쉬운 emppircial loss function 으로 나타내는 방법이 있다. expected 는 empirical loss function으로 근사한다.\n",
    "\n",
    "이전의 예제에서 mse function은 하나의 expected loss function 이고 LS FUNCTION은 empirical version 이라고 할 수 있다.\n",
    "\n",
    "<img src=\"picture_ch3/캡처19.png\" width=600 />\n",
    "\n",
    "approximation error은 generalization error 를 나타내는 것이고estimation error는 expected loss 대신 empirical loss 를 사용 해서 나타난 에러이다. 만약 family of functions 이 크다면 (dimension이 크다면? cover하는 범위가 크다면?...)  approximation error은 작아질 것이고 estimation error 는 커질 것이다. 즉 overfitting 되는 것이다. 반대의 문제도 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.15 NONPARAMETRIC MODELING AND ESTIMATION\n",
    "\n",
    "nonparametric modeling은 파라미터 모델링과 다르게 모델이 파라미터를 포함하고 있지 않거나 제외(pop-up??)되어 있다. 파라미터 모델링에서 family of functions을 선택하는 것 대신에 non파라미터에서는 specific functional space를 설정한다. \n",
    "\n",
    "이번 장에서 non파라미터 모델링을 unknown pdf의 근사의 방법으로 사용 할 것이다. 이런 방법은 매우 오래되었지만 여전히 쓰이는 모델이다.\n",
    "\n",
    "xn ∈ R, n = 1, 2, . . . ,N, 의 데이터가 있을때 unknown pdf를 그린 결과이다.\n",
    "\n",
    "<img src=\"picture_ch3/캡처20.png\" width=600 />\n",
    "\n",
    "\n",
    "h - bin , x^ - middle point , Kn - count \n",
    "\n",
    "$p(x) = \\frac{1}{h}\\frac{k_N}N, if|x − ˆx| ≤ \\frac{h}{2}$\n",
    "\n",
    "즉 주어진 데이터로 히스토그램을 그려서 p^(x) 를 추정..\n",
    "\n",
    "이런 히스토그램을 그려서 pdf 를 근사 시킬 수 있다. h - bin 값을 작게 할 수록 상대도수(kN/N) 는 좋은 추정치가 된다. 또한 관측치가 많을 수록 더 좋은 근사치를 가진다.\n",
    "\n",
    "a h=0.25 N=100   \n",
    "b h= 0.25 N=10^5   \n",
    "c h = 0.1 N =100   \n",
    "d h=0.1 N = 10^5  \n",
    "\n",
    "히스토그램 근사 방법을 실제로 적용하기 위해서 \n",
    "\n",
    "h 를 정하고 h 마다의 갯수를 구한다. interval [x − h/2, x + h/2]의 범위가 될것이다. 그후 위에서 주어졌던 식을 적용 시키면 된다.\n",
    "\n",
    "<img src=\"picture_ch3/캡처21.png\" width=600 />\n",
    "\n",
    "summation 안이 이해가안가는데..\n",
    "\n",
    ">이부분에서\n",
    ">$if|x − ˆx| ≤ \\frac{h}{2}$   \n",
    ">$\\frac{|x − ˆx| }{h}≤\\frac{1}{2}$\n",
    "\n",
    "결국 summation 은 interval [x − h/2, x +\n",
    "h/2] 인 부분을 모두 카운트 해주라는 뜻이다. 이런 방법은 정통적이지 않은 방법인데 연속적인 함수를 불연속 하게 만들기 때문이다. 또한 이런 알고리즘은 매우 느리고 데이터가 많을때 계산량이 매우 많다.\n",
    "\n",
    "파첸은 연속적인 함수를 불연속 하게 만드는 것을 해결하기 위한 방법을 제시했다.\n",
    "\n",
    "φ(x) ≥ 0 and $\\intφ(x) dx = 1,$\n",
    "\n",
    "을 만족하는 함수들을 사용하는 것을 제안 했고 이런 함수들을 kernel,potential functions, parzen windows라고한다.\n",
    "\n",
    "http://carstart.tistory.com/192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
