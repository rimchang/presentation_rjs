{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이전 장 복습\n",
    "\n",
    "## A/B TEST\n",
    "\n",
    "### 과학자 vs 사업가\n",
    "\n",
    "인터넷 쇼핑몰 운영자인 데비 널은 사이트의 레이아웃을 변경하면 사용자들이 좀 더 편안하게 느낄 것이라고 생각을 했다. 고객들이 웹사이트를 편안하게 느끼면 그것이 곧 매출의 상승으로 일어날 것이라고 생각!\n",
    "\n",
    "### 과학자\n",
    "\n",
    "통제된 상황에서의 실험을 하자!! A/B 테스트를 통해 어떤 레이아웃이 좋은지 판단 할 수 있어!\n",
    "\n",
    "<img src=\"https://vwo.com/images/page_features/split_3,402x.png.pagespeed.ce.lXJH0A97MH.png\" width=600 />\n",
    "\n",
    "### 사업가\n",
    "\n",
    "사이트의 수익이 가장 중요해!! 실험에 드는 비용은 어떻게 할 것인가?? A/B 테스트를 하는 동안 conversion(전환율 - 클릭율, 구매율 등등 우리가 설정한 목표치) 이 올라간다면 다행이겠지만... 이게 떨어진다면??? 우리는 그런 손해를 감수 할 수가 없어... 새로운 아이디어가 없다면 기존의 안을 유지하는 것이 최선이다.\n",
    "\n",
    "### 탐색-활용 딜레마\n",
    "\n",
    "위와 같은 과학자 vs 사업가의 관점을 탐색 - 활용 딜레마라고 한다. <strong>더 나은 안을 찾기 위한 <font color=red>탐색</font></strong> vs <strong>기존의 안 중에서 최선을 택하는 <font color=red>활용</font></strong> \n",
    "\n",
    "이런 탐색과 활용의 중간지점을 찾을순 없을까?\n",
    "\n",
    "\n",
    "### 여러안이 존재 한다면?\n",
    "\n",
    "<img src=\"http://unbounce.wpengine.netdna-cdn.com/photos/ab-testing.png\" width=600 />\n",
    "\n",
    "A/B B/C A/C 테스트를 해야하는건가??? - 이런 문제 때문에 Multi-armed Bandit 가 필요하다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-armed Bandit\n",
    "\n",
    "<img src=\"http://sanghyukchun.github.io/images/post/96-4.jpg\" width=300 />\n",
    "\n",
    "MAB이라는 말은 슬롯머신을 One-Armed bandit (외팔이 도둑놈, 슬롯머신에 있는 손잡이를 지칭)이라고 부르는 데서 기인한 재미있는 이름이다.\n",
    "\n",
    "정 확한 승률을 알지 못하는 여러 대의 슬롯머신을 가지고 도박을 할 때 가장 많은 돈을 따기 위해서 어떤 전략(알고리즘)을 가지고 게임을 해야 가장 많은 돈을 딸 수 있을 것인가 하는 문제를 빗대어서 잡아당길 수 있는 손잡이를 여러 개 가진 슬롯머신을 MAB이라고 부르게 된 것이다.\n",
    "\n",
    "슬롯머신에서의   \n",
    "- 활용 - 지금까지 돌려봤던 슬롯머신중 가장 높은 이익을 내는 슬롯머신을 돌리기!!   \n",
    "- 탐색 - 더 나은 이익을 내는 슬롯 머신을 찾기 위해 다른 슬롯 머신을 돌려보자!!  - 랜덤적으로\n",
    "\n",
    "웹사이트의 레이아웃을 정하는 것도 똑같은 문제이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 용어정리\n",
    "\n",
    "### 보상 Reward  \n",
    "성공success의 양적 측정(값). 비즈니스 측면에서는 궁극적인 보상이 이익이지만,\n",
    "책에서는 광고 클릭률 또는 신규 사용자 등록률과 같이 간단한 메트릭metric를 보\n",
    "상으로 다룬다. 중요한 것은 (A) 명확한 ‘양적 측정 등급quantitative scale’이 있는가와\n",
    "(B) 보상을 적게 하는 것보다는 많이 하는 것이 좋은가다.\n",
    "\n",
    "### 암 Arm\n",
    "어떤 옵션option이 우리에게 유용한가? 어떤 행동을 우리가 취할 수 있는가? 책에서\n",
    "는 사용 가능한 옵션을 ‘암Aarm’으로 지칭할 것이다. 멀티암드 밴디트 문제에 관한\n",
    "역사의 일부를 듣고 나면 이렇게 명명한 이유를 쉽게 이해할 수 있을 것이다.\n",
    "\n",
    "### 밴디트 Bandit\n",
    "‘밴디트Bandit’는 암들의 집합이다. 유용한 옵션을 많이 가지고 있을 때 이 옵션의\n",
    "집합을 ‘멀티암드 밴디트Multiarmed Bandit’라 한다. 멀티암드 밴디트는, 여러분이 취\n",
    "할 수 있는 행동이 많을 때와 이 행동을 수행한 후 얻게 될 보상에 대해 불완전한 정\n",
    "보를 가지고 있을 때, 결정을 내리는 법을 추론하는 데 사용할 수 있는 수학적 모델\n",
    "이다. 이 책에서 제시된 이 알고리즘은 언제 어느 암을 당길지 결정하는 문제를 해\n",
    "결하기 위한 방법이다. 잡아당길 암을 선택하는 문제를 ‘멀티암드 밴디트 문제’라\n",
    "부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엡실론-그리디 알고리즘\n",
    "\n",
    "이론적으로, 실험적으로 우수하지는 않지만 매우 직관적인 알고리즘\n",
    "\n",
    "### 탐욕 알고리즘(그리디 알고리즘) \n",
    "\n",
    "매 순간마다 최선의 선택을 하는 알고리즘 - 미래를 생각하지 않는다.\n",
    "\n",
    "ex) 거스름돈 문제 - 최소의 동전수로 거슬러 줘야한다.\n",
    "\n",
    "1원,7원,10원의 동전이 있다고 가정!!\n",
    "\n",
    "15원을 거슬러줘야 한다면\n",
    "\n",
    "10원,1원 * 5 으로 거슬러 줄것이다.\n",
    "\n",
    "14원을 거슬러줘야 한다면\n",
    "\n",
    "10원, 1원 * 4 로 거슬러 줄것인데...\n",
    "\n",
    "사실 7원 2개가 적절한 해답이다..\n",
    "\n",
    "\n",
    "### 위의 그리디 알고리즘과 엡실론(확률)을 결합\n",
    "\n",
    "1−ε의 확률로 지금까지 관측한 arm 중에 가장 좋은 arm을 고르고 (exploitation), ε의 확률로 나머지 arm 중에서 random한 arm을 골라서 play하는 (explore) 알고리즘이다.\n",
    "\n",
    "- 1−ε의 확률로 지금까지 empirical reward가 가장 좋은 arm을 고른다. <font color=red>- 활용</font>\n",
    "\n",
    "- ε의 확률로 uniformly random하게 arm을 고른다.<font color=red>- 탐색</font>\n",
    "\n",
    "\n",
    "<img src=\"http://conversionxl.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-04-at-4.17.36-PM-1-568x424.jpg\" width=500 />\n",
    "\n",
    "단점 \n",
    "\n",
    "- 시간이 많이 지나서 가장 좋은 arm 이 무엇인지 알게 되었더라도 계속해서 ε의 확률로 탐색을 함\n",
    "\n",
    "- ε의 확률로 탐색을 하고 탐색의 arm 중에서 관측이 되지 않는 arm이 생기게 될 가능성이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엡실론-그리디 알고리즘 구현\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class EpsilonGreedy(object):\n",
    "    \n",
    "    def __init__(self, epsilon, counts=[], values=[]):\n",
    "        self.epsilon = epsilon # e 값 지정\n",
    "        self.counts = counts # 가지고 있는데 데이터\n",
    "        self.values = values \n",
    "        \n",
    "    def initialize(self, n_arms): # 값 초기화\n",
    "        self.counts = [0 for col in range(n_arms)]\n",
    "        self.values = [0.0 for col in range(n_arms)]\n",
    "        \n",
    "    \n",
    "    def select_arm(self):\n",
    "        if random.random() > self.epsilon:\n",
    "            return self.values.index(max(self.values))\n",
    "        else:\n",
    "            return random.randrange(len(self.values))\n",
    "        \n",
    "    def update(self, chosen_arm, reward):\n",
    "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward # 이동평균\n",
    "        self.values[chosen_arm] = new_value\n",
    "        \n",
    "    def print_props(self):\n",
    "        print(self.epsilon,self.counts,self.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 이동평균으로 구하지?? 처음에는 new_value = (value+reward)/2 라고 구현 하면 되지않나라고 생각했지만..  \n",
    "\n",
    "((100+110)/2+110)/2 와\n",
    "(100+110+110)/3 은 다르다!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_greedy.initialize(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [0, 0] [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "my_greedy.print_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_greedy=EpsilonGreedy(0.1,[2,0],[100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [2, 0] [100, 0]\n"
     ]
    }
   ],
   "source": [
    "my_greedy.print_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.00616787075015\n"
     ]
    }
   ],
   "source": [
    "select_arm_index=my_greedy.select_arm()\n",
    "if select_arm_index==0:\n",
    "    reward=random.gauss(100, 10)\n",
    "else:\n",
    "    reward=random.gauss(105, 10)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_greedy.update(select_arm_index,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [1, 0] [89.00616787075015, 0.0]\n"
     ]
    }
   ],
   "source": [
    "my_greedy.print_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for :  0\n",
      "reward :  98.18612125383581\n",
      "0.1 [3, 0] [99.39537375127858, 0]\n",
      "for :  1\n",
      "reward :  104.35108716239299\n",
      "0.1 [4, 0] [100.63430210405718, 0]\n",
      "for :  2\n",
      "reward :  92.65763409595634\n",
      "0.1 [5, 0] [99.03896850243703, 0]\n",
      "for :  3\n",
      "reward :  113.69107654803717\n",
      "0.1 [6, 0] [101.48098651003707, 0]\n",
      "for :  4\n",
      "reward :  90.67773779820573\n",
      "0.1 [7, 0] [99.93766526548973, 0]\n",
      "for :  5\n",
      "reward :  113.19453857479327\n",
      "0.1 [8, 0] [101.59477442915266, 0]\n",
      "for :  6\n",
      "reward :  109.89449175131796\n",
      "0.1 [9, 0] [102.51696524272658, 0]\n",
      "for :  7\n",
      "reward :  87.31450376706358\n",
      "0.1 [10, 0] [100.99671909516029, 0]\n",
      "for :  8\n",
      "reward :  106.94101471553728\n",
      "0.1 [10, 1] [100.99671909516029, 106.94101471553728]\n",
      "for :  9\n",
      "reward :  111.17448887911209\n",
      "0.1 [10, 2] [100.99671909516029, 109.05775179732468]\n",
      "for :  10\n",
      "reward :  101.58735833415483\n",
      "0.1 [10, 3] [100.99671909516029, 106.56762064293473]\n",
      "for :  11\n",
      "reward :  100.44194568442819\n",
      "0.1 [10, 4] [100.99671909516029, 105.0362019033081]\n",
      "for :  12\n",
      "reward :  91.69849409026807\n",
      "0.1 [10, 5] [100.99671909516029, 102.3686603407001]\n",
      "for :  13\n",
      "reward :  92.70941627678344\n",
      "0.1 [10, 6] [100.99671909516029, 100.75878633004733]\n",
      "for :  14\n",
      "reward :  91.14221803196871\n",
      "0.1 [11, 6] [100.10085536214287, 100.75878633004733]\n",
      "for :  15\n",
      "reward :  92.90792984112966\n",
      "0.1 [11, 7] [100.10085536214287, 99.63723540305908]\n",
      "for :  16\n",
      "reward :  71.91288304632977\n",
      "0.1 [12, 7] [97.75185766915844, 99.63723540305908]\n",
      "for :  17\n",
      "reward :  117.88080234077135\n",
      "0.1 [12, 8] [97.75185766915844, 101.9176812702731]\n",
      "for :  18\n",
      "reward :  102.58922867381497\n",
      "0.1 [12, 9] [97.75185766915844, 101.99229764844442]\n",
      "for :  19\n",
      "reward :  102.93369980206278\n",
      "0.1 [12, 10] [97.75185766915844, 102.08643786380625]\n",
      "for :  20\n",
      "reward :  95.45230583127704\n",
      "0.1 [12, 11] [97.75185766915844, 101.48333495175814]\n",
      "for :  21\n",
      "reward :  105.17457668794931\n",
      "0.1 [12, 12] [97.75185766915844, 101.79093842977406]\n",
      "for :  22\n",
      "reward :  99.10735133153794\n",
      "0.1 [12, 13] [97.75185766915844, 101.58450865298667]\n",
      "for :  23\n",
      "reward :  109.51538133443064\n",
      "0.1 [12, 14] [97.75185766915844, 102.1509995588041]\n",
      "for :  24\n",
      "reward :  94.107938642207\n",
      "0.1 [12, 15] [97.75185766915844, 101.61479549769764]\n",
      "for :  25\n",
      "reward :  91.3350562294752\n",
      "0.1 [13, 15] [97.25825755841358, 101.61479549769764]\n",
      "for :  26\n",
      "reward :  122.13369991738512\n",
      "0.1 [13, 16] [97.25825755841358, 102.89722702392811]\n",
      "for :  27\n",
      "reward :  96.09521702980204\n",
      "0.1 [13, 17] [97.25825755841358, 102.49710878897952]\n",
      "for :  28\n",
      "reward :  103.26237467028336\n",
      "0.1 [13, 18] [97.25825755841358, 102.53962356016307]\n",
      "for :  29\n",
      "reward :  95.0285974810411\n",
      "0.1 [13, 19] [97.25825755841358, 102.144306398104]\n",
      "for :  30\n",
      "reward :  106.57452666483337\n",
      "0.1 [13, 20] [97.25825755841358, 102.36581741144047]\n",
      "for :  31\n",
      "reward :  90.78615250828071\n",
      "0.1 [13, 21] [97.25825755841358, 101.81440479700429]\n",
      "for :  32\n",
      "reward :  106.69701446155514\n",
      "0.1 [13, 22] [97.25825755841358, 102.03634159993842]\n",
      "for :  33\n",
      "reward :  120.8011837744091\n",
      "0.1 [13, 23] [97.25825755841358, 102.85220430317628]\n",
      "for :  34\n",
      "reward :  94.24935818655601\n",
      "0.1 [13, 24] [97.25825755841358, 102.49375238165044]\n",
      "for :  35\n",
      "reward :  103.52072582647678\n",
      "0.1 [13, 25] [97.25825755841358, 102.5348313194435]\n",
      "for :  36\n",
      "reward :  96.1048998694809\n",
      "0.1 [13, 26] [97.25825755841358, 102.28752626367572]\n",
      "for :  37\n",
      "reward :  108.5288842514414\n",
      "0.1 [13, 27] [97.25825755841358, 102.51868767062999]\n",
      "for :  38\n",
      "reward :  103.67964736372372\n",
      "0.1 [13, 28] [97.25825755841358, 102.5601505168119]\n",
      "for :  39\n",
      "reward :  112.17553161487726\n",
      "0.1 [13, 29] [97.25825755841358, 102.89171538226243]\n",
      "for :  40\n",
      "reward :  119.27180141907071\n",
      "0.1 [13, 30] [97.25825755841358, 103.43771825015604]\n",
      "for :  41\n",
      "reward :  112.78236116395034\n",
      "0.1 [13, 31] [97.25825755841358, 103.7391583441494]\n",
      "for :  42\n",
      "reward :  86.74152412885944\n",
      "0.1 [13, 32] [97.25825755841358, 103.20798227492159]\n",
      "for :  43\n",
      "reward :  96.94198366880003\n",
      "0.1 [13, 33] [97.25825755841358, 103.01810352928155]\n",
      "for :  44\n",
      "reward :  84.36104566881477\n",
      "0.1 [14, 33] [96.33702813772796, 103.01810352928155]\n",
      "for :  45\n",
      "reward :  109.62721650431897\n",
      "0.1 [14, 34] [96.33702813772796, 103.21248920501795]\n",
      "for :  46\n",
      "reward :  99.6999414249865\n",
      "0.1 [14, 35] [96.33702813772796, 103.11213069701705]\n",
      "for :  47\n",
      "reward :  117.3254013575638\n",
      "0.1 [14, 36] [96.33702813772796, 103.50694377092113]\n",
      "for :  48\n",
      "reward :  99.65592088611973\n",
      "0.1 [14, 37] [96.33702813772796, 103.4028620713319]\n",
      "for :  49\n",
      "reward :  104.1782852373665\n",
      "0.1 [14, 38] [96.33702813772796, 103.42326794412229]\n",
      "for :  50\n",
      "reward :  97.78633506113994\n",
      "0.1 [14, 39] [96.33702813772796, 103.278731203533]\n",
      "for :  51\n",
      "reward :  116.64108713249801\n",
      "0.1 [14, 40] [96.33702813772796, 103.61279010175711]\n",
      "for :  52\n",
      "reward :  106.82546108242782\n",
      "0.1 [14, 41] [96.33702813772796, 103.69114793055397]\n",
      "for :  53\n",
      "reward :  102.45258869354608\n",
      "0.1 [14, 42] [96.33702813772796, 103.66165842491091]\n",
      "for :  54\n",
      "reward :  81.15934616184148\n",
      "0.1 [14, 43] [96.33702813772796, 103.13834883739766]\n",
      "for :  55\n",
      "reward :  113.87009335147049\n",
      "0.1 [14, 44] [96.33702813772796, 103.3822521218084]\n",
      "for :  56\n",
      "reward :  93.04657423157758\n",
      "0.1 [14, 45] [96.33702813772796, 103.15257039091439]\n",
      "for :  57\n",
      "reward :  109.2574717365588\n",
      "0.1 [14, 46] [96.33702813772796, 103.28528563755883]\n",
      "for :  58\n",
      "reward :  106.03077460967539\n",
      "0.1 [14, 47] [96.33702813772796, 103.34370029654004]\n",
      "for :  59\n",
      "reward :  96.80923520736614\n",
      "0.1 [14, 48] [96.33702813772796, 103.20756560718225]\n",
      "for :  60\n",
      "reward :  91.49295400444218\n",
      "0.1 [14, 49] [96.33702813772796, 102.96849190100387]\n",
      "for :  61\n",
      "reward :  96.11364307539327\n",
      "0.1 [14, 50] [96.33702813772796, 102.83139492449166]\n",
      "for :  62\n",
      "reward :  108.65265944311395\n",
      "0.1 [14, 51] [96.33702813772796, 102.94553736603326]\n",
      "for :  63\n",
      "reward :  99.83619605908814\n",
      "0.1 [14, 52] [96.33702813772796, 102.8857423408997]\n",
      "for :  64\n",
      "reward :  112.5806749256597\n",
      "0.1 [14, 53] [96.33702813772796, 103.06866559721593]\n",
      "for :  65\n",
      "reward :  104.95995809936859\n",
      "0.1 [14, 54] [96.33702813772796, 103.10368953244098]\n",
      "for :  66\n",
      "reward :  111.61918247371946\n",
      "0.1 [14, 55] [96.33702813772796, 103.25851667682785]\n",
      "for :  67\n",
      "reward :  114.86603701558133\n",
      "0.1 [14, 56] [96.33702813772796, 103.46579382573415]\n",
      "for :  68\n",
      "reward :  111.29329413090416\n",
      "0.1 [14, 57] [96.33702813772796, 103.60311839249151]\n",
      "for :  69\n",
      "reward :  118.2467404366838\n",
      "0.1 [14, 58] [96.33702813772796, 103.85559463463275]\n",
      "for :  70\n",
      "reward :  116.99893011429066\n",
      "0.1 [14, 59] [96.33702813772796, 104.07836303259306]\n",
      "for :  71\n",
      "reward :  91.48642871126042\n",
      "0.1 [14, 60] [96.33702813772796, 103.86849746057085]\n",
      "for :  72\n",
      "reward :  117.36261606739349\n",
      "0.1 [14, 61] [96.33702813772796, 104.08971251969909]\n",
      "for :  73\n",
      "reward :  74.23813689239563\n",
      "0.1 [14, 62] [96.33702813772796, 103.60823549345226]\n",
      "for :  74\n",
      "reward :  106.65966029062655\n",
      "0.1 [15, 62] [97.02520361458787, 103.60823549345226]\n",
      "for :  75\n",
      "reward :  96.0439692958846\n",
      "0.1 [15, 63] [97.02520361458787, 103.48816777603054]\n",
      "for :  76\n",
      "reward :  111.00069717947642\n",
      "0.1 [15, 64] [97.02520361458787, 103.60555104795938]\n",
      "for :  77\n",
      "reward :  120.06281579364082\n",
      "0.1 [15, 65] [97.02520361458787, 103.85873973635448]\n",
      "for :  78\n",
      "reward :  107.64406941685576\n",
      "0.1 [15, 66] [97.02520361458787, 103.91609321636207]\n",
      "for :  79\n",
      "reward :  86.87029610836218\n",
      "0.1 [15, 67] [97.02520361458787, 103.66167833415311]\n",
      "for :  80\n",
      "reward :  81.19614573334937\n",
      "0.1 [16, 67] [96.03588749701046, 103.66167833415311]\n",
      "for :  81\n",
      "reward :  116.31599149144706\n",
      "0.1 [16, 68] [96.03588749701046, 103.84777117470156]\n",
      "for :  82\n",
      "reward :  78.83367936886742\n",
      "0.1 [16, 69] [96.03588749701046, 103.4852481050518]\n",
      "for :  83\n",
      "reward :  132.90025395221852\n",
      "0.1 [16, 70] [96.03588749701046, 103.90546247429704]\n",
      "for :  84\n",
      "reward :  116.6230641860997\n",
      "0.1 [16, 71] [96.03588749701046, 104.0845836251675]\n",
      "for :  85\n",
      "reward :  99.48836593975456\n",
      "0.1 [16, 72] [96.03588749701046, 104.02074726842565]\n",
      "for :  86\n",
      "reward :  85.87574429822484\n",
      "0.1 [16, 73] [96.03588749701046, 103.77218558390234]\n",
      "for :  87\n",
      "reward :  100.37474693125299\n",
      "0.1 [16, 74] [96.03588749701046, 103.72627425075844]\n",
      "for :  88\n",
      "reward :  99.13022275689542\n",
      "0.1 [17, 74] [96.21790721818016, 103.72627425075844]\n",
      "for :  89\n",
      "reward :  116.60619582565252\n",
      "0.1 [17, 75] [96.21790721818016, 103.8980065384237]\n",
      "for :  90\n",
      "reward :  104.40095020257019\n",
      "0.1 [18, 75] [96.67252071731293, 103.8980065384237]\n",
      "for :  91\n",
      "reward :  100.92203914731785\n",
      "0.1 [18, 76] [96.67252071731293, 103.85884907275125]\n",
      "for :  92\n",
      "reward :  113.31598560375528\n",
      "0.1 [18, 77] [96.67252071731293, 103.98166902769937]\n",
      "for :  93\n",
      "reward :  85.10029083355477\n",
      "0.1 [18, 78] [96.67252071731293, 103.7396000764924]\n",
      "for :  94\n",
      "reward :  125.29440123775362\n",
      "0.1 [18, 79] [96.67252071731293, 104.01244566081216]\n",
      "for :  95\n",
      "reward :  109.0808174507904\n",
      "0.1 [18, 80] [96.67252071731293, 104.07580030818688]\n",
      "for :  96\n",
      "reward :  110.00636397003319\n",
      "0.1 [18, 81] [96.67252071731293, 104.14901714351832]\n",
      "for :  97\n",
      "reward :  111.09509472106775\n",
      "0.1 [18, 82] [96.67252071731293, 104.23372540665916]\n",
      "for :  98\n",
      "reward :  98.60824640438541\n",
      "0.1 [18, 83] [96.67252071731293, 104.16594855121008]\n",
      "for :  99\n",
      "reward :  99.66985890234487\n",
      "0.1 [18, 84] [96.67252071731293, 104.11242367443788]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    select_arm_index=my_greedy.select_arm()\n",
    "    if select_arm_index==0:\n",
    "        reward=random.gauss(100, 10)\n",
    "    else:\n",
    "        reward=random.gauss(105, 10)\n",
    "    my_greedy.update(select_arm_index,reward)\n",
    "    print(\"for : \",i)\n",
    "    print(\"reward : \",reward)\n",
    "    my_greedy.print_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
